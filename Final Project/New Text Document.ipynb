{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jrUU_5AlMHk"
      },
      "source": [
        "# Machine Learning-Based Transcriptomic Biomarker Discovery in Huntington's Disease\n",
        "\n",
        "**Project:** Discovery of Key Biomarkers for Huntington's Disease Using Meta-Analysis and Machine Learning\n",
        "**Data Source:** GSE64810 (Pre-processed & Filtered)\n",
        "**Methodology:** **K-Fold Cross-Validation with SMOTE and MCC** for robust evaluation.\n",
        "**Models:** Random Forest (Feature Selection) & Support Vector Machine (Classification)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4kw-A4LlMHm"
      },
      "source": [
        "## 1. Setup and Data Loading\n",
        "Import necessary libraries and upload the `HD_ML_Ready_Data.csv` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoXKs2nIlMHm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc, matthews_corrcoef\n",
        "from imblearn.over_sampling import SMOTE # For handling imbalance\n",
        "from imblearn.pipeline import Pipeline # For cross-validation integrity\n",
        "\n",
        "# Setup plotting style\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYqDGPzklMHn"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload 'HD_ML_Ready_Data.csv'\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check if file is uploaded\n",
        "filename = list(uploaded.keys())[0]\n",
        "print(f\"Loaded file: {filename}\")\n",
        "\n",
        "data = pd.read_csv(filename)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-Vy4k2dlMHn"
      },
      "source": [
        "## 2. Data Preprocessing\n",
        "Encoding the target variable and setting up the Stratified K-Fold strategy for robust evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX0feDfvlMHn"
      },
      "outputs": [],
      "source": [
        "# Separate Features (Genes) and Target\n",
        "X = data.drop('Target_Class', axis=1)\n",
        "y = data['Target_Class']\n",
        "\n",
        "# Encode Target (Control -> 0, HD -> 1)\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "class_names = le.classes_\n",
        "print(f\"Class Mapping: {dict(zip(class_names, le.transform(class_names)))}\")\n",
        "print(f\"Control Samples: {np.sum(y_encoded == 0)}, HD Samples: {np.sum(y_encoded == 1)}\\n\")\n",
        "\n",
        "# Define K-Fold Strategy (K=5 is a common choice for smaller datasets)\n",
        "K = 5\n",
        "skf = StratifiedKFold(n_splits=K, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"Total Samples: {X.shape[0]}\")\n",
        "print(f\"Number of Features (Genes): {X.shape[1]}\")\n",
        "print(f\"Using {K}-Fold Stratified Cross-Validation with SMOTE for balance.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUextnEglMHn"
      },
      "source": [
        "## 3. Cross-Validation and Model Training\n",
        "We use **Pipelines** to ensure **SMOTE** (Synthetic Minority Over-sampling Technique) and **Standardization** only happen on the training data within each fold, preventing data leakage. We evaluate using **Matthew Correlation Coefficient (MCC)** for balanced performance assessment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_On49NplMHn"
      },
      "outputs": [],
      "source": [
        "# Initialize lists to store metrics for each fold\n",
        "rf_metrics = {'accuracy': [], 'auc': [], 'mcc': []}\n",
        "svm_metrics = {'accuracy': [], 'auc': [], 'mcc': []}\n",
        "rf_tpr_list = []\n",
        "svm_tpr_list = []\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "final_rf_pipeline = None # Store the final pipeline for subsequent steps\n",
        "final_svm_pipeline = None\n",
        "y_test_final = None\n",
        "\n",
        "print(f\"\\n--- Running {K}-Fold Cross-Validation ---\")\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y_encoded)):\n",
        "    print(f\"--- Fold {fold+1}/{K} ---\")\n",
        "    \n",
        "    # Split data for the current fold\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y_encoded[train_index], y_encoded[test_index]\n",
        "    \n",
        "    # --- Random Forest with SMOTE Pipeline ---\n",
        "    # RF does not require scaling, so we just use SMOTE -> RF\n",
        "    rf_pipeline = Pipeline([\n",
        "        ('smote', SMOTE(random_state=42)), # Oversample minority class (HD)\n",
        "        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "    rf_pipeline.fit(X_train, y_train)\n",
        "    y_pred_rf = rf_pipeline.predict(X_test)\n",
        "    y_prob_rf = rf_pipeline.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Calculate Metrics\n",
        "    rf_metrics['accuracy'].append(accuracy_score(y_test, y_pred_rf))\n",
        "    rf_metrics['auc'].append(roc_auc_score(y_test, y_prob_rf))\n",
        "    rf_metrics['mcc'].append(matthews_corrcoef(y_test, y_pred_rf))\n",
        "    \n",
        "    # Store ROC curve data for mean plotting\n",
        "    fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
        "    rf_tpr_list.append(np.interp(mean_fpr, fpr_rf, tpr_rf))\n",
        "    rf_tpr_list[-1][0] = 0.0\n",
        "\n",
        "    # --- SVM with Scaler and SMOTE Pipeline ---\n",
        "    # SVM requires scaling, so the pipeline ensures scaling is done correctly after splitting and before SMOTE\n",
        "    svm_pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()), # Scale is fit ONLY on X_train\n",
        "        ('smote', SMOTE(random_state=42)),\n",
        "        ('classifier', SVC(kernel='linear', probability=True, random_state=42))\n",
        "    ])\n",
        "    svm_pipeline.fit(X_train, y_train)\n",
        "    y_pred_svm = svm_pipeline.predict(X_test)\n",
        "    y_prob_svm = svm_pipeline.predict_proba(X_test)[:, 1]\n",
        "    \n",
        "    # Calculate Metrics\n",
        "    svm_metrics['accuracy'].append(accuracy_score(y_test, y_pred_svm))\n",
        "    svm_metrics['auc'].append(roc_auc_score(y_test, y_prob_svm))\n",
        "    svm_metrics['mcc'].append(matthews_corrcoef(y_test, y_pred_svm))\n",
        "\n",
        "    # Store ROC curve data for mean plotting\n",
        "    fpr_svm, tpr_svm, _ = roc_curve(y_test, y_prob_svm)\n",
        "    svm_tpr_list.append(np.interp(mean_fpr, fpr_svm, tpr_svm))\n",
        "    svm_tpr_list[-1][0] = 0.0\n",
        "    \n",
        "    # Store the final pipeline and test data from the last fold for subsequent cells\n",
        "    final_rf_pipeline = rf_pipeline\n",
        "    final_svm_pipeline = svm_pipeline\n",
        "    y_test_final = y_test\n",
        "    y_pred_rf_final = y_pred_rf\n",
        "    y_pred_svm_final = y_pred_svm\n",
        "\n",
        "# Calculate Mean ROC Curves and AUC for visualization and summary\n",
        "mean_tpr_rf = np.mean(rf_tpr_list, axis=0)\n",
        "mean_tpr_rf[-1] = 1.0\n",
        "mean_auc_rf = auc(mean_fpr, mean_tpr_rf)\n",
        "\n",
        "mean_tpr_svm = np.mean(svm_tpr_list, axis=0)\n",
        "mean_tpr_svm[-1] = 1.0\n",
        "mean_auc_svm = auc(mean_fpr, mean_tpr_svm)\n",
        "\n",
        "\n",
        "print(\"\\n--- Cross-Validation Summary ---\")\n",
        "print(f\"Random Forest Mean Accuracy: {np.mean(rf_metrics['accuracy']):.4f} (+/- {np.std(rf_metrics['accuracy']):.4f})\")\n",
        "print(f\"Random Forest Mean MCC: {np.mean(rf_metrics['mcc']):.4f} (+/- {np.std(rf_metrics['mcc']):.4f})\")\n",
        "print(f\"Random Forest Mean ROC-AUC: {mean_auc_rf:.4f}\")\n",
        "\n",
        "print(f\"SVM Mean Accuracy: {np.mean(svm_metrics['accuracy']):.4f} (+/- {np.std(svm_metrics['accuracy']):.4f})\")\n",
        "print(f\"SVM Mean MCC: {np.mean(svm_metrics['mcc']):.4f} (+/- {np.std(svm_metrics['mcc']):.4f})\")\n",
        "print(f\"SVM Mean ROC-AUC: {mean_auc_svm:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5L-qS7UlMHn"
      },
      "source": [
        "## 4. Evaluation and Visualization\n",
        "Plotting the mean ROC curves from the K-Fold CV runs and presenting the Confusion Matrix and Classification Report from the last fold as an example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjmnWW4XlMHo"
      },
      "outputs": [],
      "source": [
        "# --- Plot Mean ROC Curves ---\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(mean_fpr, mean_tpr_rf, label=f'Random Forest (Mean AUC = {mean_auc_rf:.2f})', lw=2)\n",
        "plt.plot(mean_fpr, mean_tpr_svm, label=f'SVM (Mean AUC = {mean_auc_svm:.2f})', lw=2)\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Mean ROC Curves (5-Fold CV with SMOTE)')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n",
        "\n",
        "# --- Plot Confusion Matrices (Last Fold Example) ---\n",
        "cm_rf = confusion_matrix(y_test_final, y_pred_rf_final)\n",
        "cm_svm = confusion_matrix(y_test_final, y_pred_svm_final)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "axes[0].set_title('Random Forest Confusion Matrix (Last Fold)')\n",
        "axes[0].set_ylabel('Actual')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "\n",
        "sns.heatmap(cm_svm, annot=True, fmt='d', cmap='Greens', ax=axes[1],\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "axes[1].set_title('SVM Confusion Matrix (Last Fold)')\n",
        "axes[1].set_ylabel('Actual')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed Classification Report for the last fold\n",
        "print(\"\\n--- Detailed Classification Report (Last Fold) ---\")\n",
        "print(f\"Random Forest MCC: {matthews_corrcoef(y_test_final, y_pred_rf_final):.4f}\")\n",
        "print(classification_report(y_test_final, y_pred_rf_final, target_names=class_names))\n",
        "\n",
        "print(f\"SVM MCC: {matthews_corrcoef(y_test_final, y_pred_svm_final):.4f}\")\n",
        "print(classification_report(y_test_final, y_pred_svm_final, target_names=class_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQawTpAKlMHo"
      },
      "source": [
        "## 5. Feature Importance (Biomarker Identification)\n",
        "We extract the feature importance from the Random Forest model trained on the final fold, which identifies the top candidate biomarkers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JobyhwqalMHo"
      },
      "outputs": [],
      "source": [
        "# Extract the classifier step from the final RF pipeline\n",
        "rf_classifier = final_rf_pipeline.named_steps['classifier']\n",
        "\n",
        "importances = rf_classifier.feature_importances_\n",
        "indices = np.argsort(importances)[::-1][:20] # Top 20 features\n",
        "\n",
        "top_genes = X.columns[indices]\n",
        "top_importances = importances[indices]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(x=top_importances, y=top_genes, palette='viridis')\n",
        "plt.title('Top 20 Candidate Biomarkers (Random Forest Importance)')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Gene ID')\n",
        "plt.show()\n",
        "\n",
        "print(\"Top 10 Genes:\")\n",
        "for gene, score in zip(top_genes[:10], top_importances[:10]):\n",
        "    print(f\"{gene}: {score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgNz44CvlMHo"
      },
      "source": [
        "## 6. Save and Download Models\n",
        "We save the final trained pipelines (which contain the SMOTE and Classifier steps) along with the feature names and encoder for future use and deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5h_l9mgzlMHo"
      },
      "outputs": [],
      "source": [
        "# Create a directory for artifacts\n",
        "!mkdir -p hd_models\n",
        "\n",
        "# 1. Save Random Forest Pipeline (includes SMOTE and RF model)\n",
        "joblib.dump(final_rf_pipeline, 'hd_models/rf_pipeline.pkl')\n",
        "\n",
        "# 2. Save SVM Pipeline (includes Scaler, SMOTE, and SVM model)\n",
        "joblib.dump(final_svm_pipeline, 'hd_models/svm_pipeline.pkl')\n",
        "\n",
        "# 3. Save Feature Names (To ensure future input order matches training)\n",
        "feature_names = list(X.columns)\n",
        "joblib.dump(feature_names, 'hd_models/feature_names.pkl')\n",
        "\n",
        "# 4. Save Label Encoder (To decode 0/1 back to Control/HD)\n",
        "joblib.dump(le, 'hd_models/label_encoder.pkl')\n",
        "\n",
        "print(\"Artifacts saved locally in 'hd_models/' folder.\")\n",
        "\n",
        "# Zip the folder\n",
        "!zip -r hd_models.zip hd_models\n",
        "\n",
        "# Download the zip file\n",
        "files.download('hd_models.zip')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}